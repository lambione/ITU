{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises 3: Linear Regression\n",
    "\n",
    "The following lab-session is adapted from that of Section 3.6 in Introduction to Statistical Learning with R.\n",
    "\n",
    "\n",
    "We use the Boston data set, which records `medv` (median house value) for 506 census tracts in Boston. We will seek to predict\n",
    "medv using 12 predictors such as `rm` (average number of rooms per house), `age` (average age of houses), and `lstat` (percent of households with low socioeconomic status).\n",
    "\n",
    "\n",
    "(A useful reference for working with linear regressions in statsmodels is https://www.statsmodels.org/stable/examples/notebooks/generated/interactions_anova.html)\n",
    "\n",
    "There are three main ways of fitting a linear regression with Python: \n",
    "* The `OLS` method from statsmodels.api\n",
    "* The `ols` method from statsmodels.formula.api\n",
    "  This method allows us to specify models ``R-style'' rather than via\n",
    "  the design matrix (see e.g.\\\n",
    "  \\url{https://www.statsmodels.org/dev/example\\_formulas.html}).\\\\\n",
    "\n",
    "  Note that, in the formula, you can specify that X is a factor as\n",
    "  `C(X)`. Also note that anything enclosed in ``the identity\n",
    "  function'' `I()` will be taken literally; for instance, \n",
    "  $\\texttt{I}(x_1*x_2)$ gives a new variable with the numeric product\n",
    "  of variables $x_1$ and $x_2$.\n",
    "* The method `LinearRegression` from `linear_model` in `sklearn`.\n",
    "\n",
    "You are encouraged to try all three methods. When you read the manual pages, note that outcome Y is referred to as the\n",
    "endogenous variable and features X as the exogenous variable(s).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "import numpy as np\n",
    "from pandas import read_csv, DataFrame\n",
    "from math import log, sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "## to be able to specify models as Y ~ lstat we need the formula API\n",
    "from statsmodels.formula.api import ols "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load data from csv; change the directory as you need!\n",
    "Boston = read_csv(\"Boston.csv\")\n",
    "Boston.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Linear Regression (i.e. with one explanatory variable)\n",
    "\n",
    "We will start by fitting a simple linear regression model, with `medv` as the response and `lstat`  as the predictor: $medv = \\beta_0 + \\beta_1 lstat + \\epsilon$\n",
    "\n",
    "First plot the response `medv` against `lstat` and see what the relationship looks like, so that you have an idea what the result may be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Boston['lstat']\n",
    "## Need an intercept in the model, so we add the constant feature \n",
    "X = sm.add_constant(X)\n",
    "sm_model = sm.OLS(Boston['medv'], X)\n",
    "lm1 = sm_model.fit()\n",
    "lm1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively specify via the formula API\n",
    "# ols(\"medv ~ 1 + lstat\", Boston).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get the estimated parameters directly from the model. A confidence interval for model coefficients is found in the model summary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Coefficients beta:\n",
    "lm1.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard error of residuals -- the square root of the estimated variance $\\sigma^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt(lm1.mse_resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Estimated variance mse_resid is computed as RSS divided by the residual degrees of freedom \n",
    "## (found as \"DF residuals\" in summary and df_resid in model object\n",
    "(lm1.resid**2).sum()/lm1.df_resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Yet another way of obtaining the variance \n",
    "lm1.ssr/lm1.df_resid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Predictions, confidence intervals, and prediction intervals\n",
    "\n",
    "We can get a prediction--the estimated mean value of `medv` for a specific value of `lstat`--for any new datapoint. To get an idea of uncertainty in the model, we can look at \n",
    "- a confidence interval for the value of the regression line to indicate how much the line itself would vary if fitted on new data.\n",
    "- a prediction interval to indicates the range in which we expect the outcome to fall. \n",
    "\n",
    "Here we compute the 95% confidence- and prediction intervals (specified as alpha = 0.05 = 1-0.95)\n",
    "\n",
    "A. Make again a scatterplot of `medv` against `lstat` and draw the regression line on top using get_prediction() to calculate the fitted values (if you just want them for the data that you used for fitting the model, you could also get them directly from the model object as `fittedvalues`). Here is an example predicting on the observations in the Boston data set -- try to replace `X` with a new dataset containing your favourite values of the explanatory variable. \n",
    "\n",
    "B. Add two curves to show the upper and lower confidence limits as a function of `lstat`.\n",
    "\n",
    "C. Add two curves to show the upper and lower prediction limits as well.\n",
    "\n",
    "Comment on the plot and, in particular, note how the prediction intervals contain the confidence interval for the predicted value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predicting on a new dataset (here just the original one X)\n",
    "pred1 = lm1.get_prediction(X)\n",
    "## Results of prediction in a dataframe\n",
    "pred1_df = pred1.summary_frame(alpha=0.05)\n",
    "pred1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A. Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B. Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C. Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the matrix formula for the parameter estimates, implement a function that takes the estimated parameters and a new feature value x and returns the predicted value $\\hat y$. (Try to vectorize it such that you can give\n",
    "it multiple new input values and get multiple predictions out). Check that you get the same as obtaining the\n",
    "predicted values from the linear regression directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model checking methods\n",
    "\n",
    "We can obtain relevant quantities either directly from the results of a linear model or from its method get_influence(). Here is an overview.\n",
    "\n",
    "From the model fit we have\n",
    "- Raw residuals: resid\n",
    "\n",
    "From get_influence() we have \n",
    "- Studentized residuals: resid_studentized_internal ($\\beta$ estimated leaving out observation $i$)\n",
    "- Externally studentized residuals: resid_studentized_external ($\\beta$ and $\\sigma^2$ both estimated leaving out observation $i$)\n",
    "- hatvalues: This is also called leverage and are the diagonal elements $h_{ii}$ of the hatmatrix $X(X^TX)^{-1}X^T$. Obtained as hat_matrix_diag\n",
    "- Cook's distance: cooks_distance\n",
    "\n",
    "To get the classical standardised residuals $e_i/\\sqrt{\\hat\\sigma^2(1-h_{ii})}$ we seem to need to do the scaling ourselves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infl = lm1.get_influence()\n",
    "\n",
    "## Obtaining standardised residuals\n",
    "SE_of_residuals = np.sqrt(lm1.mse_resid*(1-infl.hat_matrix_diag))\n",
    "stdres = np.divide(lm1.resid, SE_of_residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is the assumption of Gaussian errors reasonable? \n",
    "Compare standardised residuals to a standard normal distribution\n",
    "\n",
    "Plot the standardised residuals ordered from smallest to highest against the quantiles from a standard normal distribution. To get the latter, for N datapoints (and thus N residuals) in your data you compute the standard normal quantile for the N probabilities (1/(N+1), ..., N/(N+1)). It is good practice to make the plot square. Statsmodels also has a built-in function to make this quantile-quantile plot.\n",
    "\n",
    "What do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.qqplot(stdres, line='45'); ## Compare to standard normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can also use the studentized residuals for this kind of check. \n",
    "## With this much data, it will not make much of a difference. \n",
    "## They should be compared to a t-distribution with n-p-1 degrees of freedom (df_resid)\n",
    "import scipy.stats as stats\n",
    "sm.qqplot(lm1.get_influence().resid_studentized_internal, # observed residuals \n",
    "          stats.t, distargs=(lm1.df_resid,), #compare with quantiles of t-distribution \n",
    "          line = '45'  #reference line\n",
    "         );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is there any systematic trend in the residuals?\n",
    "\n",
    "To inspect this, make the following two types of plots:\n",
    "1. The raw residuals $y_i- \\hat y_i$ against the explanatory variable `lstat`.\n",
    "2. The raw residuals against the fitted values $\\hat y_i$. \n",
    "\n",
    "The first type of plot is relatively straightforward in revealing whether variation is small or large for certain values of the explanatory variables. It can require a bit of practice to interpret systematic trends in the second plot, but think of it as inspecting variation around the regression surface at different heights of the surface.\n",
    "\n",
    "In the plots, try to assess whether\n",
    "- there are any curvatures or other trends; the points should be nicely scattered around a horizontal line in 0.\n",
    "- there is evidence of non-homogeneous variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Influential observations\n",
    "\n",
    "You can think of leverage (diagonal elements of the hat matrix) as flags for *potentially* influential observations. Leverages are always bigger than 1/n, and they sum to the number of variables in the model, $p$. If the observation **also has a high studentized residual** --- the residual obtained when using the regression fitted *without the observation* $(x_i, y_i)$ --- then it is likely to act like a magnet on the regression surface. Cook's distance is a measure that in effect flags observation with high leverage and large residuals. \n",
    "\n",
    "Taking the observations in any order (for instance row index), make three plots on top of each other: \n",
    "1. Leverage (hatvalues) against index\n",
    "2. Studentized residuals against index\n",
    "3. Cooks distance against index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression (i.e. with multiple explanatory variables)\n",
    "\n",
    "Now we make more complex models. \n",
    "\n",
    "Fit a model `lm2` that includes both `age` and `lstat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit then model `lm3` in which they enter also as a product (interaction). Note that if you include `lstat*age` using the formula API, then `lstat` and `age` are automatically added to the model -- a nice thing about formula APIs is that we only need to specify these highest order interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-linear transformations of the explanatory variables\n",
    "\n",
    "We now perform a regression of `medv` onto `lstat` and `lstat` squared. \n",
    "\n",
    "Given a predictor $X$, we can create a predictor $X^2$ using\n",
    " `I(X**2)` in the formula API. The function `I()` is needed to protect the math formula inside.\n",
    " \n",
    "When building models in practice, consider shifting your explanatory variables so that the intercept has a more interpretable meaning. For example, age=0 is rarely interesting, whereas age=25 or age=\"median value of the observed in our study\" might very well be. Typically we would center them around the mean, the median or a value with some nice interpretation. It can also help on numerical stability, especially when fitting polynomials where values get more extreme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lm4 = ols(\"medv ~ lstat + I(lstat**2)\", Boston).fit()\n",
    "lm4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactions\n",
    "Create a categorical feature by splitting `age` into three groups using cutpoints of your own choice. \n",
    "\n",
    "(a) Fit a model where the lines capturing the relationship between `medv` and `lstat` are parallel for the three\n",
    "age groups (only intercept changes)\n",
    "\n",
    "(b) Fit a model where the lines have different intercept and slope in each of the three age groups (both intercept\n",
    "and slope is unique to the group)\n",
    "\n",
    "(c) Visualize the fitted lines by predicting on new data in a specific group and on a range of `lstat`\n",
    "values (possibly much finer range than the values in the data). Plot the fitted values against the range of\n",
    "`lstat` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing two nested models against each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the two models `lm1` and `lm4` above. The model `lm1` is nested into `lm4`, since it corresponds to setting the coefficient for the squared term to zero. We here discuss three possible ways of comparing the two models, but note that there are many more (see the book for details).\n",
    "\n",
    "### Method 1: A t-test for whether a specific coefficient is zero ($\\beta_j = 0$)\n",
    "\n",
    "We can see from the summary of model lm4 that the squared term is highly significant. \n",
    "\n",
    "### Method 2: An F-test for whether several coefficients are zero \n",
    "\n",
    "The F-test based on sums of squares is much more general, in that it allows us to perform a single test addressing whether several coefficients could be zero. This could be because you want to remove several explanatory variables, or because you want to remove a single categorical variable with several groups. Even if we want to test just one coefficient, the F-test is preferable to the t-test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## output is (F-statistic, p-value of the test, degrees of freedom)\n",
    "## Here we have removed just one parameter, so the degrees of freedom is 1.\n",
    "lm4.compare_f_test(lm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using formula (3.24) in ISLwR\n",
    "difference_in_RSS = lm1.ssr - lm4.ssr\n",
    "drop_in_parameters = lm1.df_resid - lm4.df_resid\n",
    "residual_standard_error = lm4.mse_resid\n",
    "\n",
    "(difference_in_RSS/drop_in_parameters)/residual_standard_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model summary always displays the F-test for removing *all* features of the model, i.e. that *all* coefficients are zero. The test simply compares the model to the \"empty model\" with no features and only an intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm4.mse_model/lm4.mse_resid "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3: Comparing by an information criterion\n",
    "\n",
    "We can also compare models without using tests but rather some kind of \"score\" -- an information criterion -- such as AIC or BIC. For this comparison, **the models do not have to be nested**. \n",
    "\n",
    "Lower AIC is better, so we conclude also from this comparison that the model with a square term is preferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(lm4.aic, lm1.aic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following models: \n",
    "\n",
    "$Y \\sim 1 + I(1/X)$  (possibly adding X also?)\n",
    "\n",
    "$Y \\sim 1 + X + I(X^2)$\n",
    "\n",
    "Which model is better? Explain whether you would use F-test or AIC for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can you make a model that fits well?\n",
    "\n",
    "Try using the techniques for model checking and testing to guide you towards a well-fitting model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
